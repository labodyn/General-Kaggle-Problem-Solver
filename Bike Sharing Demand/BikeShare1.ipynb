{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras import models, layers, optimizers\\nfrom keras.optimizers import Adam \\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout, Embedding, LSTM, Reshape, Input, merge, GlobalAveragePooling1D, Convolution1D, AveragePooling1D, Activation, Flatten\\nfrom keras.preprocessing import sequence\\nfrom keras.models import Model\\nfrom keras.engine import topology\\nfrom keras.layers.core import Lambda\\nfrom keras import backend as K'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import scipy\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge , ElasticNet, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, train_test_split, cross_val_score, StratifiedKFold, LabelKFold, ShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt \n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import math \n",
    "#import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "'''\n",
    "from keras import models, layers, optimizers\n",
    "from keras.optimizers import Adam \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Reshape, Input, merge, GlobalAveragePooling1D, Convolution1D, AveragePooling1D, Activation, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.engine import topology\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day = pd.read_csv(\"day.csv\")\n",
    "df_hour = pd.read_csv(\"hour.csv\")\n",
    "len(df_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81          0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80          0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80          0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75          0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75          0       0           1    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAME PLAN** \n",
    "\n",
    "Let us first try to build a model for \"cnt\" in the daily dataset and then we can finetune things for the hourly \"cnt\". For the daily as well as for the hourly case, we will try to build two models: one for the \"casual cnt\" as well as for the \"registered cnt\", and then add them up later on.  \n",
    "\n",
    "**A - daily cnt analysis**\n",
    "\n",
    "**1. _Data preparation_**: watch out for missing values, normalize continuous features, convert categorical features to one-hot encoding via pd.get_dummies\n",
    "\n",
    "**2. _Feature selection_**: use lasso with various paramter \"alpha\" (the parameter that determines how aggressively features are being pushed towards 0 - so the larger alpha is, the less features will be used with the crosseponding lasso model). segment features according to how much leverage they have on each label (casual as well as registered): high leverage features, medium leverage features, low leverage features. then build intuition through various plots.\n",
    "\n",
    "**3. _Model testing_**: based on previous plots, run some basic models such as ridge regression, kNN regression, random forest, gradient boosting for the \"casual cnt\" as well as for the \"registered cnt\". We test various hyperparameter for their respective performance. We expect the \"registered cnt\" to be more predictable (by common sense). If we feel the need to be a little more fancy we can try some Poisson models, non-negative binomials or time series analysis. \n",
    "\n",
    "**4. _Outlier removal_**: if we are still unhappy we can perform some outlier removal such as storm sandy hitting DC at the end of october 2012. then test performance for the so far best performing model.\n",
    "\n",
    "**5. _Feature augmentation_**: If we are still unhappy we want to think of some feature augmentation, such as pulling data for **daylight timespan** for the daily cnt, or the **sunrise/ sunset data**, or rely on other expert knowledge. To see how relevant those features are, we can perform lasso again for various \"alpha\" values. then test performance for the so far best performing model. \n",
    "\n",
    "**6. _Clustering_**: apply differnet models for different party of the data. then test performance for the so far best performing model.  \n",
    "\n",
    "All intermediate evaluations will be done using 3-fold cross validation. once we have a winner, we will do the random test selection evaluation of size 0.1\n",
    "\n",
    "**B - hourly cnt analysis**\n",
    "\n",
    "**1. _Data preparation_**: prepare the data: watch out for missing values, normalize continuous features, convert categorical features to one-hot encoding via pd.get_dummies\n",
    "\n",
    "**2. _Feature selection_**: use lasso with various paramter \"alpha\". segment features according to how much leverage they have on each label (casual as well as registered), then build intuition through various plots.\n",
    "\n",
    "**3. _Model testing_ **\n",
    "\n",
    "**4. _Outlier removal_**\n",
    "\n",
    "**5. _Feature augmentation_** here **sunrise/ sunset data** can be interesting\n",
    "\n",
    "**6. _Clustering_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - DAILY ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 - Data preparation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
       "       'casual', 'registered', 'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**continuous features**: 'temp', 'atemp', 'hum', 'windspeed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**categorical features**: 'season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummies_season = pd.get_dummies(df_day['season']).rename(columns={1: \"Spring\", 2: \"Summer\", 3: \"Fall\", 4: \"Winter\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spring</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Spring  Summer  Fall  Winter\n",
       "0       1       0     0       0\n",
       "1       1       0     0       0\n",
       "2       1       0     0       0\n",
       "3       1       0     0       0\n",
       "4       1       0     0       0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_season.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['yr'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies_yr = pd.get_dummies(df_day['yr']).rename(columns={0: \"year 2011\", 1: \"year 2012\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year 2011</th>\n",
       "      <th>year 2012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year 2011  year 2012\n",
       "0          1          0\n",
       "1          1          0\n",
       "2          1          0\n",
       "3          1          0\n",
       "4          1          0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_yr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['mnth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies_mnth = pd.get_dummies(df_day['mnth']).rename(columns={1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\", 7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n",
       "0    1    0    0    0    0    0    0    0    0    0    0    0\n",
       "1    1    0    0    0    0    0    0    0    0    0    0    0\n",
       "2    1    0    0    0    0    0    0    0    0    0    0    0\n",
       "3    1    0    0    0    0    0    0    0    0    0    0    0\n",
       "4    1    0    0    0    0    0    0    0    0    0    0    0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies_mnth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['holiday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['holiday'].sum() # ok so 1 is holiday and 0 is no holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['weekday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "Name: weekday, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day[df_day['dteday']=='2011-01-01']['weekday'] # Jan 1, 2011 was a Saturday so 6 is Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['workingday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['workingday'].sum() # so 1 is workings day, and 0 is non workingday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['weathersit'].unique() # huh? no weathersit 4?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummies_holiday = pd.get_dummies(df_day['holiday']).rename(columns={0: \"holiday\", 1: \"non holiday\"})\n",
    "dummies_weekday = pd.get_dummies(df_day['weekday']).rename(columns={0: \"Sunday\", 1: \"Monday\", 2: \"Tuesday\", 3: \"Wednesday\", 4: \"Thursday\", 5: \"Friday\", 6: \"Saturday\"})\n",
    "dummies_workingday = pd.get_dummies(df_day['workingday']).rename(columns={0: \"workingday\", 1: \"non workingday\"})\n",
    "dummies_weathersit = pd.get_dummies(df_day['weathersit']).rename(columns={1: \"weathersit 1\", 2: \"weathersit 2\", 3: \"weathersit 3\", 4: \"weathersit 4\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bringing it all together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_day = pd.concat([df_day[['temp', 'atemp', 'hum', 'windspeed']], dummies_season, dummies_yr, dummies_mnth, dummies_holiday, dummies_weekday, dummies_workingday, dummies_weathersit], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>year 2011</th>\n",
       "      <th>year 2012</th>\n",
       "      <th>...</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>non workingday</th>\n",
       "      <th>weathersit 1</th>\n",
       "      <th>weathersit 2</th>\n",
       "      <th>weathersit 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp     atemp       hum  windspeed  Spring  Summer  Fall  Winter  \\\n",
       "0  0.344167  0.363625  0.805833   0.160446       1       0     0       0   \n",
       "1  0.363478  0.353739  0.696087   0.248539       1       0     0       0   \n",
       "2  0.196364  0.189405  0.437273   0.248309       1       0     0       0   \n",
       "3  0.200000  0.212122  0.590435   0.160296       1       0     0       0   \n",
       "4  0.226957  0.229270  0.436957   0.186900       1       0     0       0   \n",
       "\n",
       "   year 2011  year 2012      ...       Tuesday  Wednesday  Thursday  Friday  \\\n",
       "0          1          0      ...             0          0         0       0   \n",
       "1          1          0      ...             0          0         0       0   \n",
       "2          1          0      ...             0          0         0       0   \n",
       "3          1          0      ...             1          0         0       0   \n",
       "4          1          0      ...             0          1         0       0   \n",
       "\n",
       "   Saturday  workingday  non workingday  weathersit 1  weathersit 2  \\\n",
       "0         1           1               0             0             1   \n",
       "1         0           1               0             0             1   \n",
       "2         0           0               1             1             0   \n",
       "3         0           0               1             1             0   \n",
       "4         0           0               1             1             0   \n",
       "\n",
       "   weathersit 3  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_day.head() # here we see 36 features in total. now is time to use lasso and see the most relevant features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     985\n",
       "1     801\n",
       "2    1349\n",
       "3    1562\n",
       "4    1600\n",
       "Name: cnt, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the labels\n",
    "y_day = df_day['cnt']\n",
    "y_day_reg = df_day['registered']\n",
    "y_day_cas = df_day['casual']\n",
    "y_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 100 - training set score: 0.85\n",
      "alpha = 100 - test set score: 0.84\n",
      "0.982235133583\n",
      "0.885121357565\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "#new_index = np.random.permutation(X_day.index)\n",
    "#X_day = X_day.reindex(new_index)\n",
    "#y_day = y_day.reindex(new_index)\n",
    "\n",
    "X_day_train, X_day_test, y_day_train, y_day_test = train_test_split(X_day,y_day, test_size=0.2, random_state=42)\n",
    "lasso_100 = Lasso(alpha=0.1,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "print(\"alpha = 100 - training set score: %.2f\" % lasso_100.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 100 - test set score: %.2f\" % lasso_100.score(X_day_test,y_day_test))\n",
    "\n",
    "clf =RandomForestRegressor(n_estimators=1000, criterion='mse', max_depth=None, min_samples_split=2)\n",
    "myfit = clf.fit(X_day_train,y_day_train)\n",
    "print(myfit.score(X_day_train,y_day_train))\n",
    "print(myfit.score(X_day_test,y_day_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 100 - training set score: 0.67\n",
      "alpha = 100 - test set score: 0.69\n",
      "alpha = 100 - test set MAE: 834.25\n",
      "alpha = 100 - number of features used: 6\n",
      "alpha = 100 - features at play: Index(['temp', 'Spring', 'Fall', 'year 2011', 'year 2012', 'weathersit 1'], dtype='object')\n",
      "alpha = 100 - corresponding coefficients:  [  2.85721268e+02  -1.84118901e+03   3.45990631e+02  -1.66643822e+03\n",
      "   9.61348246e-13   5.09135705e+02]\n",
      "---------------------------\n",
      "alpha = 10 - training set score: 0.83\n",
      "alpha = 10 - test set score: 0.82\n",
      "alpha = 10 - test set MAE: 625.03\n",
      "alpha = 10 - number of features used: 22\n",
      "alpha = 10 - features at play: Index(['temp', 'atemp', 'Spring', 'Winter', 'year 2011', 'year 2012', 'Jan',\n",
      "       'Mar', 'May', 'Jul', 'Sep', 'Oct', 'Nov', 'Dec', 'holiday', 'Sunday',\n",
      "       'Monday', 'Tuesday', 'Thursday', 'Saturday', 'weathersit 1',\n",
      "       'weathersit 3'],\n",
      "      dtype='object')\n",
      "alpha = 10 - corresponding coefficients:  [  1.17974410e+03   3.04558450e+03  -1.27254191e+03   2.22882474e+02\n",
      "  -1.97452613e+03   7.44494118e-11  -1.78224626e+02   3.96496521e+02\n",
      "   1.58064035e+02  -2.78127803e+02   6.14224526e+02   2.14072577e+02\n",
      "  -2.70982540e+02  -1.99269642e+02   3.33925793e+02  -2.23799449e+02\n",
      "  -2.92890894e+01  -1.47602997e+01   2.14928610e+01   9.23740777e+01\n",
      "   7.32792727e+02  -1.24580359e+03]\n",
      "---------------------------\n",
      "alpha = 1 - training set score: 0.85\n",
      "alpha = 1 - test set score: 0.83\n",
      "alpha = 1 - test set MAE: 596.56\n",
      "alpha = 1 - number of features used: 27\n",
      "alpha = 1 - features at play: Index(['atemp', 'hum', 'windspeed', 'Spring', 'Winter', 'year 2011',\n",
      "       'year 2012', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Sep',\n",
      "       'Oct', 'Nov', 'Dec', 'holiday', 'Sunday', 'Monday', 'Tuesday',\n",
      "       'Thursday', 'Friday', 'Saturday', 'weathersit 1', 'weathersit 3'],\n",
      "      dtype='object')\n",
      "alpha = 1 - corresponding coefficients:  [  5.35138897e+03  -1.34262460e+03  -1.96602394e+03  -9.04929525e+02\n",
      "   7.41064400e+02  -1.95875524e+03   3.98039482e-11  -2.59833511e+02\n",
      "  -4.78576208e+01   5.59280297e+02   1.19783737e+02   3.50810296e+02\n",
      "   1.58325033e+01  -4.45002326e+02   6.90628164e+02   1.02329929e+01\n",
      "  -6.29929153e+02  -4.44703907e+02   6.38795830e+02  -2.67092589e+02\n",
      "  -1.88773388e+01  -6.17565810e+01   2.30482887e+01   2.35250983e+01\n",
      "   1.78638252e+02   5.52831914e+02  -1.14670284e+03]\n",
      "---------------------------\n",
      "alpha = 0.1 - training set score: 0.85\n",
      "alpha = 0.1 - test set score: 0.83\n",
      "alpha = 0.1 - test set MAE: 597.67\n",
      "alpha = 0.1 - number of features used: 31\n",
      "alpha = 0.1 - features at play: Index(['temp', 'atemp', 'hum', 'windspeed', 'Spring', 'Summer', 'Fall',\n",
      "       'Winter', 'year 2011', 'year 2012', 'Jan', 'Feb', 'Mar', 'Apr', 'May',\n",
      "       'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'holiday', 'Sunday',\n",
      "       'Monday', 'Tuesday', 'Thursday', 'Friday', 'Saturday', 'weathersit 1',\n",
      "       'weathersit 3'],\n",
      "      dtype='object')\n",
      "alpha = 0.1 - corresponding coefficients:  [ -2.92327188e+00   5.44312458e+03  -1.48481479e+03  -2.18600125e+03\n",
      "  -1.06748867e+03  -2.79662599e+02  -1.63749569e+02   6.09827103e+02\n",
      "  -1.95496827e+03   4.43180915e-11  -2.38355761e+02  -3.16017413e+01\n",
      "   6.36429298e+02   2.65735880e+02   4.83880391e+02   9.56195520e+01\n",
      "  -4.63215333e+02  -1.68712955e+01   7.00524274e+02   7.02844946e+00\n",
      "  -6.49494659e+02  -4.48263899e+02   6.73691351e+02  -2.68929661e+02\n",
      "  -9.33649420e+00  -6.23422109e+01   2.23806139e+01   3.05777195e+01\n",
      "   1.85770717e+02   5.33219979e+02  -1.13797951e+03]\n",
      "---------------------------\n",
      "alpha = 0.01 - training set score: 0.85\n",
      "alpha = 0.01 - test set score: 0.83\n",
      "alpha = 0.01 - test set MAE: 598.74\n",
      "alpha = 0.01 - number of features used: 32\n",
      "alpha = 0.01 - features at play: Index(['temp', 'atemp', 'hum', 'windspeed', 'Spring', 'Summer', 'Fall',\n",
      "       'Winter', 'year 2011', 'year 2012', 'Jan', 'Feb', 'Mar', 'Apr', 'May',\n",
      "       'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'holiday', 'Sunday',\n",
      "       'Monday', 'Tuesday', 'Thursday', 'Friday', 'Saturday', 'weathersit 1',\n",
      "       'weathersit 2', 'weathersit 3'],\n",
      "      dtype='object')\n",
      "alpha = 0.01 - corresponding coefficients:  [ -1.17957287e+03   6.69057558e+03  -1.50417851e+03  -2.13563206e+03\n",
      "  -1.16103267e+03  -3.97295463e+02  -2.67816623e+02   5.12215901e+02\n",
      "  -1.95660023e+03   7.95106359e-11  -2.57814629e+02  -5.01282633e+01\n",
      "   6.31586314e+02   2.73182249e+02   5.07585663e+02   1.33808546e+02\n",
      "  -4.38306204e+02   1.11660680e+01   7.20136787e+02  -4.33289480e-01\n",
      "  -6.65406941e+02  -4.66417978e+02   6.63745551e+02  -2.69303926e+02\n",
      "  -1.60477817e+01  -5.94428362e+01   2.55535253e+01   3.15051391e+01\n",
      "   1.87786065e+02   5.88422035e+02   5.73018797e+01  -1.06993459e+03]\n",
      "---------------------------\n",
      "alpha = 0.001 - training set score: 0.85\n",
      "alpha = 0.001 - test set score: 0.83\n",
      "alpha = 0.001 - test set MAE: 598.88\n",
      "alpha = 0.001 - number of features used: 32\n",
      "alpha = 0.001 - features at play: Index(['temp', 'atemp', 'hum', 'windspeed', 'Spring', 'Summer', 'Fall',\n",
      "       'Winter', 'year 2011', 'year 2012', 'Jan', 'Feb', 'Mar', 'Apr', 'May',\n",
      "       'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'holiday', 'Sunday',\n",
      "       'Monday', 'Tuesday', 'Thursday', 'Friday', 'Saturday', 'weathersit 1',\n",
      "       'weathersit 2', 'weathersit 3'],\n",
      "      dtype='object')\n",
      "alpha = 0.001 - corresponding coefficients:  [ -1.30310176e+03   6.82070725e+03  -1.50607647e+03  -2.13011572e+03\n",
      "  -1.16638159e+03  -4.05482259e+02  -2.74853509e+02   5.06823296e+02\n",
      "  -1.95680495e+03   1.38858243e-11  -2.58192936e+02  -5.03512626e+01\n",
      "   6.32974238e+02   2.76095172e+02   5.12309884e+02   1.40221901e+02\n",
      "  -4.33047695e+02   1.69882730e+01   7.24513991e+02  -2.45101791e-05\n",
      "  -6.65697773e+02  -4.66871611e+02   6.62525121e+02  -2.69378765e+02\n",
      "  -1.68161593e+01  -5.91270274e+01   2.58800487e+01   3.15817393e+01\n",
      "   1.88023316e+02   5.93060853e+02   6.21618188e+01  -1.06396422e+03]\n"
     ]
    }
   ],
   "source": [
    "# lasso for the total cnt number\n",
    "\n",
    "lasso_100 = Lasso(alpha=100,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_10 = Lasso(alpha=10,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_1 = Lasso(alpha=1,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_01 = Lasso(alpha=0.1,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_001 = Lasso(alpha=0.01,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_0001 = Lasso(alpha=0.001,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "\n",
    "print(\"alpha = 100 - training set score: %.2f\" % lasso_100.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 100 - test set score: %.2f\" % lasso_100.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 100 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_100.predict(X_day_test)))\n",
    "print(\"alpha = 100 - number of features used: %d\" % np.sum(lasso_100.coef_ !=0))\n",
    "print(\"alpha = 100 - features at play:\", X_day.columns[lasso_100.coef_ !=0])\n",
    "print(\"alpha = 100 - corresponding coefficients: \", lasso_100.coef_[lasso_100.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 10 - training set score: %.2f\" % lasso_10.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 10 - test set score: %.2f\" % lasso_10.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 10 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_10.predict(X_day_test)))\n",
    "print(\"alpha = 10 - number of features used: %d\" % np.sum(lasso_10.coef_ !=0))\n",
    "print(\"alpha = 10 - features at play:\", X_day.columns[lasso_10.coef_ !=0])\n",
    "print(\"alpha = 10 - corresponding coefficients: \", lasso_10.coef_[lasso_10.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 1 - training set score: %.2f\" % lasso_1.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 1 - test set score: %.2f\" % lasso_1.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 1 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_1.predict(X_day_test)))\n",
    "print(\"alpha = 1 - number of features used: %d\" % np.sum(lasso_1.coef_ !=0))\n",
    "print(\"alpha = 1 - features at play:\", X_day.columns[lasso_1.coef_ !=0])\n",
    "print(\"alpha = 1 - corresponding coefficients: \", lasso_1.coef_[lasso_1.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 0.1 - training set score: %.2f\" % lasso_01.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 0.1 - test set score: %.2f\" % lasso_01.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 0.1 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_01.predict(X_day_test)))\n",
    "print(\"alpha = 0.1 - number of features used: %d\" % np.sum(lasso_01.coef_ !=0))\n",
    "print(\"alpha = 0.1 - features at play:\", X_day.columns[lasso_01.coef_ !=0])\n",
    "print(\"alpha = 0.1 - corresponding coefficients: \", lasso_01.coef_[lasso_01.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 0.01 - training set score: %.2f\" % lasso_001.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 0.01 - test set score: %.2f\" % lasso_001.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 0.01 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_001.predict(X_day_test)))\n",
    "print(\"alpha = 0.01 - number of features used: %d\" % np.sum(lasso_001.coef_ !=0))\n",
    "print(\"alpha = 0.01 - features at play:\", X_day.columns[lasso_001.coef_ !=0])\n",
    "print(\"alpha = 0.01 - corresponding coefficients: \", lasso_001.coef_[lasso_001.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 0.001 - training set score: %.2f\" % lasso_0001.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 0.001 - test set score: %.2f\" % lasso_0001.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 0.001 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_0001.predict(X_day_test)))\n",
    "print(\"alpha = 0.001 - number of features used: %d\" % np.sum(lasso_0001.coef_ !=0))\n",
    "print(\"alpha = 0.001 - features at play:\", X_day.columns[lasso_0001.coef_ !=0])\n",
    "print(\"alpha = 0.001 - corresponding coefficients: \", lasso_0001.coef_[lasso_0001.coef_ !=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_100 = Lasso(alpha=100,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_10 = Lasso(alpha=10,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_1 = Lasso(alpha=1,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_01 = Lasso(alpha=0.1,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_001 = Lasso(alpha=0.01,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "lasso_0001 = Lasso(alpha=0.001,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "\n",
    "print(\"alpha = 100 - training set score: %.2f\" % lasso_100.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 100 - test set score: %.2f\" % lasso_100.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 100 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_100.predict(X_day_test)))\n",
    "print(\"alpha = 100 - number of features used: %d\" % np.sum(lasso_100.coef_ !=0))\n",
    "print(\"alpha = 100 - features at play:\", X_day.columns[lasso_100.coef_ !=0])\n",
    "print(\"alpha = 100 - corresponding coefficients: \", lasso_100.coef_[lasso_100.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 10 - training set score: %.2f\" % lasso_10.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 10 - test set score: %.2f\" % lasso_10.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 10 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_10.predict(X_day_test)))\n",
    "print(\"alpha = 10 - number of features used: %d\" % np.sum(lasso_10.coef_ !=0))\n",
    "print(\"alpha = 10 - features at play:\", X_day.columns[lasso_10.coef_ !=0])\n",
    "print(\"alpha = 10 - corresponding coefficients: \", lasso_10.coef_[lasso_10.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 1 - training set score: %.2f\" % lasso_1.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 1 - test set score: %.2f\" % lasso_1.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 1 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_1.predict(X_day_test)))\n",
    "print(\"alpha = 1 - number of features used: %d\" % np.sum(lasso_1.coef_ !=0))\n",
    "print(\"alpha = 1 - features at play:\", X_day.columns[lasso_1.coef_ !=0])\n",
    "print(\"alpha = 1 - corresponding coefficients: \", lasso_1.coef_[lasso_1.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 0.1 - training set score: %.2f\" % lasso_01.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 0.1 - test set score: %.2f\" % lasso_01.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 0.1 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_01.predict(X_day_test)))\n",
    "print(\"alpha = 0.1 - number of features used: %d\" % np.sum(lasso_01.coef_ !=0))\n",
    "print(\"alpha = 0.1 - features at play:\", X_day.columns[lasso_01.coef_ !=0])\n",
    "print(\"alpha = 0.1 - corresponding coefficients: \", lasso_01.coef_[lasso_01.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 0.01 - training set score: %.2f\" % lasso_001.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 0.01 - test set score: %.2f\" % lasso_001.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 0.01 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_001.predict(X_day_test)))\n",
    "print(\"alpha = 0.01 - number of features used: %d\" % np.sum(lasso_001.coef_ !=0))\n",
    "print(\"alpha = 0.01 - features at play:\", X_day.columns[lasso_001.coef_ !=0])\n",
    "print(\"alpha = 0.01 - corresponding coefficients: \", lasso_001.coef_[lasso_001.coef_ !=0])\n",
    "print(\"---------------------------\")\n",
    "print(\"alpha = 0.001 - training set score: %.2f\" % lasso_0001.score(X_day_train,y_day_train))\n",
    "print(\"alpha = 0.001 - test set score: %.2f\" % lasso_0001.score(X_day_test,y_day_test))\n",
    "print(\"alpha = 0.001 - test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_0001.predict(X_day_test)))\n",
    "print(\"alpha = 0.001 - number of features used: %d\" % np.sum(lasso_0001.coef_ !=0))\n",
    "print(\"alpha = 0.001 - features at play:\", X_day.columns[lasso_0001.coef_ !=0])\n",
    "print(\"alpha = 0.001 - corresponding coefficients: \", lasso_0001.coef_[lasso_0001.coef_ !=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'sunrise_sunset_2011.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-bc4882bf5dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msunrise_sunset_2011\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sunrise_sunset_2011.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# source: http://aa.usno.navy.mil/data/docs/RS_OneYear.php\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lander/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lander/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lander/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lander/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/lander/anaconda3/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: File b'sunrise_sunset_2011.txt' does not exist"
     ]
    }
   ],
   "source": [
    "sunrise_sunset_2011 = pd.read_table('sunrise_sunset_2011.txt', delim_whitespace=True)\n",
    "# source: http://aa.usno.navy.mil/data/docs/RS_OneYear.php "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sunrise_sunset_2011' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-8e2f8540eefc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msunrise_sunset_2011\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sunrise_sunset_2011' is not defined"
     ]
    }
   ],
   "source": [
    "sunrise_sunset_2011.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting to know the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## daily cnt analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1        0        6           0   \n",
       "1        2  2011-01-02       1   0     1        0        0           0   \n",
       "2        3  2011-01-03       1   0     1        0        1           1   \n",
       "3        4  2011-01-04       1   0     1        0        2           1   \n",
       "4        5  2011-01-05       1   0     1        0        3           1   \n",
       "\n",
       "   weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0           2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1           2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2           1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3           1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4           1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "\n",
       "    cnt  \n",
       "0   985  \n",
       "1   801  \n",
       "2  1349  \n",
       "3  1562  \n",
       "4  1600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1045b87f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAHmCAYAAAC/AnzdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10460d4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "week = 19\n",
    "df_day['cnt'][7*week:7*week+ 7].plot(kind='bar')\n",
    "df_day['casual'][7*week:7*week+ 7].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11cc52390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAHeCAYAAABXK/kdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRitFjmxDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cc58160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "week = 10\n",
    "df_day['cnt'][7*week:7*week+ 7].plot(kind='bar')\n",
    "df_day['registered'][7*week:7*week+ 7].plot(kind='bar', color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## daily casual cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_day= pd.concat([ df_day[['temp','atemp','hum','windspeed']],pd.get_dummies(df_day['season']), pd.get_dummies(df_day['yr']),pd.get_dummies(df_day['mnth']), pd.get_dummies(df_day['holiday']),pd.get_dummies(df_day['weekday']),pd.get_dummies(df_day['workingday']), pd.get_dummies(df_day['weathersit'])], axis=1)\n",
    "y_day_cas = df_day['casual']\n",
    "X_day_cas_train, X_day_cas_test, y_day_cas_train, y_day_cas_test = train_test_split(X_day,y_day_cas, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.25\n",
      "test set score: 0.25\n",
      "test set MAE: 453.82\n",
      "number of features used: 2\n"
     ]
    }
   ],
   "source": [
    "lasso_day_cas = Lasso(alpha=100,max_iter = 1000000).fit(X_day_cas_train,y_day_cas_train)\n",
    "print(\"training set score: %.2f\" % lasso_day_cas.score(X_day_cas_train,y_day_cas_train))\n",
    "print(\"test set score: %.2f\" % lasso_day_cas.score(X_day_cas_test,y_day_cas_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_cas_test, lasso_day_cas.predict(X_day_cas_test)))\n",
    "print(\"number of features used: %d\" % np.sum(lasso_day_cas.coef_ !=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    0.        ,   -0.        ,   -0.        ,\n",
       "       -154.75609567,    0.        ,    0.        ,   -0.        ,\n",
       "         -0.        ,    0.        ,   -0.        ,   -0.        ,\n",
       "         -0.        ,    0.        ,    0.        ,    0.        ,\n",
       "          0.        ,    0.        ,    0.        ,    0.        ,\n",
       "         -0.        ,   -0.        ,    0.        ,   -0.        ,\n",
       "          0.        ,   -0.        ,   -0.        ,   -0.        ,\n",
       "         -0.        ,   -0.        ,    0.        ,  312.52962385,\n",
       "         -0.        ,    0.        ,   -0.        ,   -0.        ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_day_cas.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     'temp',     'atemp',       'hum', 'windspeed',           1,\n",
       "                 2,           3,           4,           0,           1,\n",
       "                 1,           2,           3,           4,           5,\n",
       "                 6,           7,           8,           9,          10,\n",
       "                11,          12,           0,           1,           0,\n",
       "                 1,           2,           3,           4,           5,\n",
       "                 6,           0,           1,           1,           2,\n",
       "                 3],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_day.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([1, 0], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_day.columns[lasso_day_cas.coef_ != 0] # relevant features: workingday > season 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.69\n",
      "test set score: 0.72\n",
      "test set MAE: 281.13\n",
      "number of features used: 14\n"
     ]
    }
   ],
   "source": [
    "lasso_day_cas = Lasso(alpha=10,max_iter = 1000000).fit(X_day_cas_train,y_day_cas_train)\n",
    "print(\"training set score: %.2f\" % lasso_day_cas.score(X_day_cas_train,y_day_cas_train))\n",
    "print(\"test set score: %.2f\" % lasso_day_cas.score(X_day_cas_test,y_day_cas_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_cas_test, lasso_day_cas.predict(X_day_cas_test)))\n",
    "print(\"number of features used: %d\" % np.sum(lasso_day_cas.coef_ !=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     'temp',     'atemp',       'hum', 'windspeed',           1,\n",
       "                 2,           4,           0,           1,           2,\n",
       "                 3,           4,           5,           6,           7,\n",
       "                 8,           9,          10,          12,           0,\n",
       "                 1,           0,           1,           2,           3,\n",
       "                 4,           5,           6,           0,           1,\n",
       "                 1,           2,           3],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_day.columns[lasso_day_cas.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.75\n",
      "test set score: 0.72\n",
      "test set MAE: 253.25\n",
      "number of features used: 33\n"
     ]
    }
   ],
   "source": [
    "lasso_day_cas = Lasso(alpha=0.001,max_iter = 1000000).fit(X_day_cas_train,y_day_cas_train)\n",
    "print(\"training set score: %.2f\" % lasso_day_cas.score(X_day_cas_train,y_day_cas_train))\n",
    "print(\"test set score: %.2f\" % lasso_day_cas.score(X_day_cas_test,y_day_cas_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_cas_test, lasso_day_cas.predict(X_day_cas_test)))\n",
    "print(\"number of features used: %d\" % np.sum(lasso_day_cas.coef_ !=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.97\n",
      "test set score: 0.761\n",
      "test set MAE: 211.70\n"
     ]
    }
   ],
   "source": [
    "rfr_day_cas = RandomForestRegressor()\n",
    "rfr_day_cas.fit(X_day_cas_train,y_day_cas_train)\n",
    "print(\"training set score: %.2f\" % rfr_day_cas.score(X_day_cas_train,y_day_cas_train))\n",
    "print(\"test set score: %.3f\" % rfr_day_cas.score(X_day_cas_test,y_day_cas_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_cas_test, rfr_day_cas.predict(X_day_cas_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.94\n",
      "test set score: 0.783\n",
      "test set MAE: 191.86\n"
     ]
    }
   ],
   "source": [
    "gbr_day_cas = GradientBoostingRegressor()\n",
    "gbr_day_cas.fit(X_day_cas_train,y_day_cas_train)\n",
    "print(\"training set score: %.2f\" % gbr_day_cas.score(X_day_cas_train,y_day_cas_train))\n",
    "print(\"test set score: %.3f\" % gbr_day_cas.score(X_day_cas_test,y_day_cas_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_cas_test, gbr_day_cas.predict(X_day_cas_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# registered daily cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_day_reg = df_day['registered']\n",
    "X_day_reg_train, X_day_reg_test, y_day_reg_train, y_day_reg_test = train_test_split(X_day,y_day_reg, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.85\n",
      "test set score: 0.88\n",
      "test set MAE: 444.23\n"
     ]
    }
   ],
   "source": [
    "def print_accuracy(model, X_train, y_train, X_test, y_test):\n",
    "    print(\"training set score: %.2f\" % model.score(X_train, y_train))\n",
    "    print(\"test set score: %.2f\" % model.score(X_test, y_test))\n",
    "    print(\"test set MAE: %.2f\" % mean_absolute_error(y_test, model.predict(X_test)))\n",
    "\n",
    "    \n",
    "lasso_day_reg = Lasso(alpha=0.001,max_iter = 1000000).fit(X_day_reg_train,y_day_reg_train)\n",
    "print_accuracy(lasso_day_reg, X_day_reg_train, y_day_reg_train, X_day_reg_test, y_day_reg_test)\n",
    "\n",
    "\n",
    "#print(\"training set score: %.2f\" % lasso_day_reg.score(X_day_reg_train,y_day_reg_train))\n",
    "#print(\"test set score: %.2f\" % lasso_day_reg.score(X_day_reg_test,y_day_reg_test))\n",
    "#print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_reg_test, lasso_day_reg.predict(X_day_reg_test)))\n",
    "#print(\"number of features used: %d\" % np.sum(lasso_day_reg.coef_ !=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.95\n",
      "test set score: 0.943\n",
      "test set MAE: 315.20\n"
     ]
    }
   ],
   "source": [
    "gbr_day_reg = GradientBoostingRegressor()\n",
    "gbr_day_reg.fit(X_day_reg_train,y_day_reg_train)\n",
    "print(\"training set score: %.2f\" % gbr_day_reg.score(X_day_reg_train,y_day_reg_train))\n",
    "print(\"test set score: %.3f\" % gbr_day_reg.score(X_day_reg_test,y_day_reg_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_reg_test, gbr_day_reg.predict(X_day_reg_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all daily cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_day = df_day['cnt']\n",
    "X_day_train, X_day_test, y_day_train, y_day_test = train_test_split(X_day,y_day, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.85\n",
      "test set score: 0.86\n",
      "test set MAE: 592.29\n",
      "number of features used: 32\n"
     ]
    }
   ],
   "source": [
    "lasso_day = Lasso(alpha=0.001,max_iter = 1000000).fit(X_day_train,y_day_train)\n",
    "print(\"training set score: %.2f\" % lasso_day.score(X_day_train,y_day_train))\n",
    "print(\"test set score: %.2f\" % lasso_day.score(X_day_test,y_day_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_test, lasso_day.predict(X_day_test)))\n",
    "print(\"number of features used: %d\" % np.sum(lasso_day.coef_ !=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.95\n",
      "test set score: 0.919\n",
      "test set MAE: 439.47\n"
     ]
    }
   ],
   "source": [
    "gbr_day = GradientBoostingRegressor()\n",
    "gbr_day.fit(X_day_train,y_day_train)\n",
    "print(\"training set score: %.2f\" % gbr_day.score(X_day_train,y_day_train))\n",
    "print(\"test set score: %.3f\" % gbr_day.score(X_day_test,y_day_test))\n",
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_test, gbr_day.predict(X_day_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_day_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499    1944.498534\n",
       "668    1724.493461\n",
       "517    1691.483617\n",
       "596    1525.640483\n",
       "692    1457.098224\n",
       "455    1350.193286\n",
       "645    1326.988826\n",
       "473    1319.204362\n",
       "441    1297.587272\n",
       "80     1217.478926\n",
       "680    1207.862376\n",
       "424    1203.357369\n",
       "396    1164.921650\n",
       "461    1142.214143\n",
       "494    1075.653257\n",
       "694    1068.365973\n",
       "101    1055.692815\n",
       "365    1005.790568\n",
       "425    1004.424619\n",
       "435     979.902031\n",
       "234     977.106689\n",
       "452     963.444507\n",
       "691     945.891619\n",
       "103     907.704832\n",
       "664     897.207973\n",
       "670     882.726038\n",
       "229     873.840289\n",
       "447     859.832871\n",
       "705     851.745737\n",
       "708     849.155949\n",
       "          ...     \n",
       "48      807.985400\n",
       "571     796.853979\n",
       "665     795.730624\n",
       "88      781.517424\n",
       "656     774.778544\n",
       "651     769.139831\n",
       "454     758.022718\n",
       "649     754.626636\n",
       "358     749.427183\n",
       "431     739.446804\n",
       "363     736.102596\n",
       "184     736.006473\n",
       "26      732.134993\n",
       "354     725.165744\n",
       "214     724.318790\n",
       "273     713.106706\n",
       "498     712.852744\n",
       "508     709.193741\n",
       "426     701.739193\n",
       "251     699.201750\n",
       "142     697.551797\n",
       "568     689.681615\n",
       "446     688.651229\n",
       "76      672.124908\n",
       "119     669.026542\n",
       "617     667.686995\n",
       "388     667.404894\n",
       "107     652.404086\n",
       "440     649.337461\n",
       "133     648.459660\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.absolute(gbr_day.predict(X_day_train)-y_day_train).nlargest(66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-05-14'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['dteday'][499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set MAE: 417.47\n"
     ]
    }
   ],
   "source": [
    "print(\"test set MAE: %.2f\" % mean_absolute_error(y_day_test, gbr_day_cas.predict(X_day_test)+gbr_day_reg.predict(X_day_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "the prediction for 'casual' is worse than for 'registered'. Most likely we should treat casual and registered separately and see how we can boost the performance for casual.  \n",
    "\n",
    "let us try neural network as well as outlier removal. neural nets can learn some pretty complex structures and fairly complex features. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 36)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_day.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_day_train, X_day_test, y_day_train, y_day_test = train_test_split(X_day,y_day, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(100, input_dim=36,init='glorot_uniform', activation='relu'))\n",
    "nn.add(Dense(100, init='glorot_uniform', activation='relu'))\n",
    "nn.add(Dense(10, init='glorot_uniform', activation='relu'))\n",
    "nn.add(Dense(10, init='glorot_uniform', activation='relu'))\n",
    "#nn.add(Dropout(dropout_probability))\n",
    "nn.add(Dense(1, init='glorot_uniform', activation='relu'))\n",
    "nn.compile(optimizer = 'adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "657"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_day_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 21556280.5209     \n",
      "performance: 2722.17162603 2764.31122156 0\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 3289367.3660     \n",
      "performance: 1159.25038906 1307.9395389 1\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 1663170.2336     \n",
      "performance: 895.757363237 978.910469674 2\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 1090558.1169     \n",
      "performance: 709.758679441 765.633726378 3\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 829571.9980     \n",
      "performance: 625.73405784 668.443839408 4\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 739321.8815     \n",
      "performance: 601.026419026 636.794544117 5\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 707740.3938     \n",
      "performance: 581.002315063 603.883839375 6\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 678981.9550     \n",
      "performance: 572.513022877 597.762343123 7\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 681437.2351     \n",
      "performance: 566.992660592 585.713872136 8\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 665550.0776     \n",
      "performance: 583.325165886 621.759731808 9\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 648717.8805     \n",
      "performance: 556.620314623 587.754166887 10\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 651469.7879     \n",
      "performance: 554.579296513 579.917099411 11\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 642320.5320     \n",
      "performance: 553.528622399 582.994133202 12\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 624534.3271     \n",
      "performance: 555.77735527 593.866996971 13\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 616499.7339     \n",
      "performance: 581.500908362 624.339124525 14\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 615991.1175     \n",
      "performance: 550.64725693 585.200889794 15\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 614202.8358     \n",
      "performance: 565.809436432 605.339018951 16\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 609293.5643     \n",
      "performance: 538.3865292 568.662409602 17\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 600182.6312     \n",
      "performance: 547.927989849 575.875912228 18\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 594144.3142     \n",
      "performance: 554.046888447 586.906466097 19\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 600492.8549     \n",
      "performance: 539.547311072 570.63285539 20\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 587754.3587     \n",
      "performance: 541.267208982 571.326927391 21\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 580988.3391     \n",
      "performance: 533.965878305 564.954612938 22\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 583843.3241     \n",
      "performance: 528.534592331 559.760625066 23\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 586879.6530     \n",
      "performance: 525.856650923 560.80748522 24\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 573935.8167     \n",
      "performance: 548.775243658 579.448771709 25\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 568186.0277     \n",
      "performance: 529.710615068 552.988960885 26\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 566880.1550     \n",
      "performance: 548.345793511 583.642074997 27\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 561628.5847     \n",
      "performance: 520.321009237 556.781235154 28\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 564267.0340     \n",
      "performance: 530.26868282 568.729264543 29\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 552937.4028     \n",
      "performance: 517.395432308 562.768138989 30\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 548990.8599     \n",
      "performance: 526.093400941 573.223434861 31\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 546454.6297     \n",
      "performance: 517.025119845 554.806434425 32\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 551382.0640     \n",
      "performance: 520.209982955 566.040606524 33\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 543576.5014     \n",
      "performance: 511.539933308 561.24338016 34\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 532746.1618     \n",
      "performance: 509.015997784 554.186665303 35\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 536180.6564     \n",
      "performance: 507.620309235 549.622594885 36\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 534652.0044     \n",
      "performance: 505.672507648 559.173788535 37\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 531033.3322     \n",
      "performance: 535.128237302 586.967179582 38\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 527116.3438     \n",
      "performance: 542.382504328 596.56883116 39\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 525474.8078     \n",
      "performance: 561.833169447 619.571361645 40\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 528835.9372     \n",
      "performance: 502.464302864 552.81480119 41\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 519446.7775     \n",
      "performance: 499.163975348 557.178552576 42\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 516106.4743     \n",
      "performance: 499.213237815 555.284140097 43\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 523164.5193     \n",
      "performance: 519.445233233 579.916436273 44\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 501489.4168     \n",
      "performance: 497.269195742 557.854279389 45\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 496043.7722     \n",
      "performance: 495.200493126 553.463349213 46\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 508390.2679     \n",
      "performance: 490.828647097 556.861813107 47\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 499602.2097     \n",
      "performance: 488.752151791 552.09707889 48\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 497507.9445     \n",
      "performance: 490.98446293 549.231438714 49\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 504742.9962     \n",
      "performance: 521.795343756 586.414075697 50\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 495882.8262     \n",
      "performance: 490.170436191 559.562387827 51\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 494663.5727     \n",
      "performance: 484.951489917 550.614892908 52\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 496068.0677     \n",
      "performance: 485.520872839 548.882959314 53\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 491163.6029     \n",
      "performance: 504.176503499 578.735684781 54\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 492098.7181     \n",
      "performance: 490.552459995 567.79847841 55\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 488911.0072     \n",
      "performance: 481.083467875 553.115646775 56\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 491324.2661     \n",
      "performance: 498.55646393 579.584588128 57\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 487550.9014     \n",
      "performance: 504.350875924 584.967234019 58\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 476139.9626     \n",
      "performance: 482.356310143 548.204739957 59\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 479828.1010     \n",
      "performance: 485.820071077 562.696282464 60\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 473468.0249     \n",
      "performance: 481.88780159 559.28811563 61\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 473789.7754     \n",
      "performance: 483.119801862 560.165933145 62\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 474821.0470     \n",
      "performance: 483.28856321 562.970551362 63\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 466821.2072     \n",
      "performance: 482.059328401 564.046843658 64\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 466554.1570     \n",
      "performance: 490.806438405 576.084286252 65\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 463174.3752     \n",
      "performance: 526.99542025 610.669512774 66\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 461111.4300     \n",
      "performance: 473.112826691 542.984609243 67\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 458142.4105     \n",
      "performance: 472.602327205 548.431516905 68\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 457382.7069     \n",
      "performance: 491.086740061 578.564195788 69\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 454140.8270     \n",
      "performance: 468.976152626 548.664628312 70\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 461209.1666     \n",
      "performance: 485.42115498 579.180517248 71\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 461558.5439     \n",
      "performance: 470.572147364 548.267409866 72\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 451940.8167     \n",
      "performance: 474.438910637 544.38560857 73\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 450439.1171     \n",
      "performance: 467.950728789 552.544973013 74\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 452055.0816     \n",
      "performance: 473.751716184 559.975343446 75\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 445949.0529     \n",
      "performance: 465.857769041 541.928339778 76\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 442167.6681     \n",
      "performance: 469.876202866 557.289847709 77\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 438484.3584     \n",
      "performance: 478.272240533 568.762922957 78\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 438894.8173     \n",
      "performance: 501.65258594 597.489642169 79\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 441447.5086     \n",
      "performance: 477.745975953 569.393536542 80\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 440083.1520     \n",
      "performance: 462.544618418 550.930702003 81\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 436190.7523     \n",
      "performance: 462.839734407 550.479488888 82\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 440385.6584     \n",
      "performance: 464.960243306 550.790753339 83\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 427894.7043     \n",
      "performance: 461.730471676 542.771385399 84\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 422970.5875     \n",
      "performance: 462.699188883 547.538288838 85\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 432062.9150     \n",
      "performance: 457.861599021 541.814499314 86\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 436810.0089     \n",
      "performance: 477.237096174 583.215327082 87\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 429042.9391     \n",
      "performance: 464.449419692 555.60555288 88\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 425247.3591     \n",
      "performance: 468.22228637 573.574997361 89\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 431875.0166     \n",
      "performance: 457.276437791 553.933933567 90\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 419164.5631     \n",
      "performance: 458.941336018 546.630318307 91\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 422337.6062     \n",
      "performance: 453.991633353 543.589281237 92\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 417373.0120     \n",
      "performance: 465.238256121 565.963916675 93\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 420050.7803     \n",
      "performance: 459.032183271 563.711890968 94\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 414623.8241     \n",
      "performance: 470.329418862 569.489445867 95\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 418477.5658     \n",
      "performance: 470.393346453 547.3622519 96\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 444436.6703     \n",
      "performance: 452.143244402 540.814840781 97\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 416404.1709     \n",
      "performance: 455.620503836 555.005265519 98\n",
      "Epoch 1/1\n",
      "657/657 [==============================] - 0s - loss: 413657.0783     \n",
      "performance: 463.937902674 577.96373522 99\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "MAE = []\n",
    "for epoch in range(n_epochs):\n",
    "    nn.fit(np.array(X_day_train), y_day_train, nb_epoch=1, batch_size=5)\n",
    "    MAE.append(mean_absolute_error(y_day_test,nn.predict(np.array(X_day_test))))\n",
    "    print(\"performance:\", mean_absolute_error(y_day_train,nn.predict(np.array(X_day_train))),mean_absolute_error(y_day_test,nn.predict(np.array(X_day_test))),epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input() got an unexpected keyword argument 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-ec6b726dffb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlstm_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input() got an unexpected keyword argument 'input_dim'"
     ]
    }
   ],
   "source": [
    "sequence = Sequential()\n",
    "lstm_layer = LSTM(15, input_dim=36)(sequence)\n",
    "output = Dense(1, init='glorot_uniform', activation = 'relu')(lstm_layer)\n",
    "lstm = Model(input = sequence, output = output)\n",
    "lstm.compile(optimizer = 'adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(15, input_dim=36))\n",
    "lstm.add(Dense(1, init='glorot_uniform', activation = 'relu'))\n",
    "lstm.compile(optimizer = 'adam', loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Error when checking model input: expected lstm_input_1 to have 3 dimensions, but got array with shape (657, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-3544b4cb1a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_day_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_day_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mMAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_day_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_day_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/keras/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/giancarlokerg/keras/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/keras/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    959\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m    962\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m    963\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/giancarlokerg/keras/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m     95\u001b[0m                                 \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                                 \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                                 str(array.shape))\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model input: expected lstm_input_1 to have 3 dimensions, but got array with shape (657, 1)"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "MAE = []\n",
    "for epoch in range(n_epochs):\n",
    "    lstm.fit(np.array(X_day_train), y_day_train, nb_epoch=1, batch_size=5)\n",
    "    MAE.append(mean_absolute_error(y_day_test,lstm.predict(np.array(X_day_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
